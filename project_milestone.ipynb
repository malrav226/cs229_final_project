{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66285b0a-b0c0-41e6-aeab-cc475a2f9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth in ./miniconda3/lib/python3.11/site-packages (from prettytable) (0.2.8)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.9.0\n"
     ]
    }
   ],
   "source": [
    "#pip install ucimlrepo-- UNCOMMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56c3d1-f844-417c-8759-52cd7267ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912c3057-dfb2-45b0-ba08-7aa51b29bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas-- UNCOMMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef2cb16-0366-455c-a75b-53fc136af322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn-- UNCOMMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f307b2-6c42-4fa1-9f06-ea0848ccbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CAN ADD SOME INTRO/BACKGROUND FROM THIS PAPER \n",
    "\n",
    "# https://academic.oup.com/gigascience/article/9/11/giaa128/6006352 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63924aeb-2e83-4916-9722-e99dc6d526fc",
   "metadata": {},
   "source": [
    "Relevant snippet copied from paper:\n",
    "\n",
    "Previously, the dataset was a subject of machine learning method applications, including convolutional neural networks [23] and dimensionality reduction methods [24].\n",
    "\n",
    "\n",
    "As a first step of pre-processing, 7 variables were removed from the initial MI complication data table as containing >30% of missing values. Next, 126 records were removed as containing >20% of the missing values. After this step, the data table contained 2.5% of missing values with 533 rows (34% of all clinical cases) having no missing values.\n",
    "\n",
    "After the missing value filtering step, the data table of MI complications contained 84 binary, 9 continuous numerical, 22 ordinal, and 1 categorical variables. The large number of ordinal variables requires careful quantification (see Methods), which is not trivial given the large number of rows with missing values.\n",
    "\n",
    "We considered the number of continuous numerical variables too small to apply the methodology of categorical principal component analysis (CatPCA) [28]. Therefore, for all ordinal and binary variables we first applied univariate quantification following the approach described in the Methods section. This quantification allowed the application of the â€œSVDComplete\" imputation method for imputing the missing values, as described in the Methods. After all missing values were imputed, we could apply the optimal scaling approach for ordinal values, optimizing the pairwise correlations between them and between ordinal and continuous numerical variables. The 22 ordinal variables quantified in this way were further used for forming the data space. In addition, all variables were converted to z-scores.\n",
    "\n",
    "\n",
    "Note: features already ordinally encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5834587-2809-4170-8132-d9698b787c9b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "514394f5-d6fa-4d16-a9af-2924e4c2adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA AND IMPORT RELEVANT PACKAGES\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "  \n",
    "# fetch dataset \n",
    "myocardial_infarction_complications = fetch_ucirepo(id=579) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = myocardial_infarction_complications.data.features \n",
    "y = myocardial_infarction_complications.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11245e35-328d-4d34-b2ad-28080d14bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF FEATURES AND OBSERVATIONS WITH A LOT OF MISSINGNESS\n",
    "\n",
    "# first, find percentage of missing values\n",
    "missing_percentage = (X.isna().sum() / len(X)) * 100\n",
    "\n",
    "# List of columns with over 30% missing values\n",
    "columns_to_remove = missing_percentage[missing_percentage > 30].index\n",
    "X = X.drop(columns = columns_to_remove)\n",
    "\n",
    "# we will also remove rows with >20% missingess\n",
    "missing_percentage_per_row = (X.isna().sum(axis=1) / X.shape[1]) * 100\n",
    "rows_to_remove = missing_percentage_per_row[missing_percentage_per_row > 20].index\n",
    "\n",
    "# Remove the identified rows from both X and Y\n",
    "X = X.drop(index=rows_to_remove)\n",
    "y = y.drop(index=rows_to_remove)\n",
    "\n",
    "# TODO: Explain this process in milestone and report the percentage of missingness in the dataframe, how many features were removed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e64bca11-a8dc-4f49-a510-23d819f37bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/w3zvknms6yvf104977q75_jm0000gn/T/ipykernel_68607/1724817802.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['any_event'] = y[events].any(axis=1).astype(int)\n",
      "/var/folders/0d/w3zvknms6yvf104977q75_jm0000gn/T/ipykernel_68607/1724817802.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['cause_of_death'] = y['LET_IS'].apply(map_to_category)\n"
     ]
    }
   ],
   "source": [
    "# CREATE NEW OUTCOME THAT IS 1 IF ANY EVENT OCCURS AND 0 IF NO EVENT OCCURS\n",
    "events = ['FIBR_PREDS', 'PREDS_TAH', 'JELUD_TAH', 'FIBR_JELUD', 'A_V_BLOK',\n",
    "       'OTEK_LANC', 'RAZRIV', 'DRESSLER', 'ZSN', 'REC_IM', 'P_IM_STEN']\n",
    "y['any_event'] = y[events].any(axis=1).astype(int)\n",
    "\n",
    "\n",
    "# CREATE NEW OUTCOME THAT GROUPS CAUSES OF DEATH TOGETHER SO WE HAVE LESS OUTCOMES\n",
    "# INSPO FROM CHATGPT (SEE BELOW)\n",
    "\n",
    "def map_to_category(cause):\n",
    "    if cause in [1, 3, 4]:\n",
    "        return 'cardiac_complications'\n",
    "    elif cause in [2, 5]:\n",
    "        return 'pulmonary_complications'\n",
    "    elif cause in [6, 7]:\n",
    "        return 'cardiac_arrest'\n",
    "    else:\n",
    "        return 'alive' \n",
    "\n",
    "y['cause_of_death'] = y['LET_IS'].apply(map_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04a92545-3ae7-4c9b-a0cb-b04ab377a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA INTO TRAIN AND TEST\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "\n",
    "# Determine which features are categorical (ordinal), continuous, and binary\n",
    "# might be helpful later\n",
    "\n",
    "unique_non_missing_values = X.nunique(dropna=True)\n",
    "unique_non_missing_values_df = unique_non_missing_values.reset_index()\n",
    "unique_non_missing_values_df.columns = ['feature', 'n_unique_values']\n",
    "\n",
    "\n",
    "continuous_features = ['AGE', 'D_AD_ORIT', 'S_AD_ORIT', 'K_BLOOD', \n",
    "                       'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', \n",
    "                       'ROE']\n",
    "\n",
    "binary_features = list(unique_non_missing_values_df[(unique_non_missing_values_df['n_unique_values'] == 2) & (~unique_non_missing_values_df['feature'].isin(continuous_features))]['feature'])\n",
    "\n",
    "ordinal_features = list(unique_non_missing_values_df[(unique_non_missing_values_df['n_unique_values'] > 2) & (~unique_non_missing_values_df['feature'].isin(continuous_features))]['feature'])\n",
    "\n",
    "\n",
    "# TODO: Note in paper that we split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2f1bc93-4b1a-4224-888c-a5e5d12ce382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5406392694063927\n",
      "0.5574468085106383\n",
      "LET_IS\n",
      "0    0.852055\n",
      "1    0.054795\n",
      "3    0.028311\n",
      "7    0.018265\n",
      "6    0.014612\n",
      "4    0.012785\n",
      "2    0.010959\n",
      "5    0.008219\n",
      "Name: proportion, dtype: float64\n",
      "LET_IS\n",
      "0    0.825532\n",
      "1    0.070213\n",
      "3    0.046809\n",
      "6    0.014894\n",
      "4    0.014894\n",
      "7    0.010638\n",
      "2    0.010638\n",
      "5    0.006383\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CHECK BALANCE IN TRAIN AND TEST SPLITS FOR 'ANY_EVENT' OUTCOME\n",
    "\n",
    "print(sum(y_train['any_event'])/len(y_train))\n",
    "print(sum(y_test['any_event'])/len(y_test))\n",
    "\n",
    "# Both around 50%! We probably do not need to rebalance for the binary classification task\n",
    "\n",
    "\n",
    "# CHECK BALANCE IN TRAIN AND TEST SPLITS FOR 'CAUSE OF DEATH' OUTCOME\n",
    "print(y_train['LET_IS'].value_counts(normalize=True))\n",
    "print(y_test['LET_IS'].value_counts(normalize=True))\n",
    "\n",
    "# we see a much greater degree of imbalance in this column, with around 85% \n",
    "# alive outcomes and only 15% being any other cause of death\n",
    "\n",
    "# TODO: In paper note the degree of balance/imbalance in all of our possible outcomes\n",
    "# TODO: Make these into nice tables for the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "cdd0be18-56f3-40a7-8de1-bd09fe4d8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIBR_PREDS    0.10\n",
      "PREDS_TAH     0.01\n",
      "JELUD_TAH     0.03\n",
      "FIBR_JELUD    0.05\n",
      "A_V_BLOK      0.03\n",
      "OTEK_LANC     0.10\n",
      "RAZRIV        0.03\n",
      "DRESSLER      0.04\n",
      "ZSN           0.24\n",
      "REC_IM        0.08\n",
      "P_IM_STEN     0.08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For individual outcomes, want to look at proportion of outcome vs. no outcome as well\n",
    "y_outcomes = y_train[events]\n",
    "proportions = (y_outcomes.sum() / len(y_outcomes)).round(2)  \n",
    "print(proportions)\n",
    "\n",
    "# TODO: Report this in fancy table in paper\n",
    "# Also include a table that shows the number/proportion of overlaps between these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1afb9d8-f94f-4f97-ad6c-cee146e6162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE MISSING VALUES ON TRAINING AND TESTING DATA\n",
    "# using simple KNN imputer for now\n",
    "\n",
    "def impute_values(X, n):\n",
    "    imputer = KNNImputer(n_neighbors=n)\n",
    "    imputed = imputer.fit_transform(X)\n",
    "    return imputed\n",
    "\n",
    "# Fit the imputer on the training data and transform train and test data\n",
    "X_train_imputed = impute_values(X_train, 5)\n",
    "X_test_imputed = impute_values(X_test, 5)\n",
    "\n",
    "#TODO: Explain this simple process in paper and note that without more knowledge on missingness we will not explore other methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ef1a8-7866-44f0-9f43-58d040909513",
   "metadata": {},
   "source": [
    "# Binary Classification with Logistic Regression\n",
    "\n",
    "We are predicting the target of any event vs. no event. These are quite balanced outcomes (see percentages above!) so we will not deal with rebalancing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb2e0636-bdd1-49f0-8ca0-d76ea381920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6829787234042554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[140,  68],\n",
       "       [ 81, 181]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN LOGISTIC REGRESSION MODEL WITH LASSO \n",
    "\n",
    "# train model\n",
    "model = LogisticRegression(penalty = \"l1\", solver='liblinear')\n",
    "model.fit(X_train_imputed, y_train['any_event'])\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['any_event'], y_pred)\n",
    "print(accuracy)\n",
    "confusion_matrix(y_test['any_event'], y_pred)\n",
    "\n",
    "# we have accuracy of almost 70% \n",
    "# can we format this confusion matrix better?\n",
    "# we can make note that accuracy feels reasonable to look at here because of class balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e557ff8-42b5-4fcb-a3be-98e816f71cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.031181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEX</td>\n",
       "      <td>-0.199716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STENOK_AN</td>\n",
       "      <td>0.028116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FK_STENOK</td>\n",
       "      <td>-0.060182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBS_POST</td>\n",
       "      <td>0.092338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LID_S_n</td>\n",
       "      <td>0.313669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ANT_CA_S_n</td>\n",
       "      <td>-0.015915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GEPAR_S_n</td>\n",
       "      <td>0.141909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ASP_S_n</td>\n",
       "      <td>0.008445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TRENT_S_n</td>\n",
       "      <td>-0.079656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0           AGE     0.031181\n",
       "1           SEX    -0.199716\n",
       "3     STENOK_AN     0.028116\n",
       "4     FK_STENOK    -0.060182\n",
       "5      IBS_POST     0.092338\n",
       "..          ...          ...\n",
       "97      LID_S_n     0.313669\n",
       "99   ANT_CA_S_n    -0.015915\n",
       "100   GEPAR_S_n     0.141909\n",
       "101     ASP_S_n     0.008445\n",
       "103   TRENT_S_n    -0.079656\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIGURE OUT WHICH FEATURES REMAINED IN THE MODEL AFTER LASSO\n",
    "\n",
    "coefficients = model.coef_\n",
    "feature_names = X_train.columns  \n",
    "feature_coefficients = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients[0]})\n",
    "selected_features = feature_coefficients[feature_coefficients['Coefficient'] != 0]\n",
    "selected_features\n",
    "\n",
    "# 65 features remain of original 104! \n",
    "\n",
    "# TODO: Explain this process in paper and print out classificaiton report\n",
    "# Note that we will also try this with a deep learning model to see if we can bump up accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa2f08-bc64-4519-8efa-112e7e86a444",
   "metadata": {},
   "source": [
    "# Multi-Class Classification with Logistic Regression\n",
    "\n",
    "We are now predicting the cause of death outcome, where as you can recall there is a great deal of class imbalance. In the training set 85% of outcomes are alive, while the remainining 15% is split between 7 different options.\n",
    "\n",
    "In writeup describe what all of these causes are.\n",
    "\n",
    "We will first try to just run a logistic regression without accounting for class imbalance at all. We will use the l1 regularization again.\n",
    "\n",
    "There are two options, one v. one and one v. rest. In the OvR strategy, you train a separate binary classifier for each class, treating it as the positive class, while considering all other classes as the negative class.\n",
    "\n",
    "OvR is often preferred when you have a large number of classes, and it can be more computationally efficient.\n",
    "It's suitable for imbalanced datasets and is less sensitive to imbalanced class distributions.\n",
    "OvR can handle both binary and multiclass classification problems without modification. \n",
    "\n",
    "We will start with OVR. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5fc1a-e22e-434d-8074-6a6a2fd5bda6",
   "metadata": {},
   "source": [
    "### Crude: No Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d031449-0558-49b9-83f1-0e30d30e68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malaviravindran/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/malaviravindran/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/malaviravindran/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', penalty = 'l1')\n",
    "model.fit(X_train_imputed, y_train['LET_IS'])\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['LET_IS'], y_pred)\n",
    "report = classification_report(y_test['LET_IS'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5452ef0b-9cf4-4562-935f-955367f43316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+----------+---------+\n",
      "| Category | precision | recall | f1-score | support |\n",
      "+----------+-----------+--------+----------+---------+\n",
      "|    0     |    0.85   |  1.00  |   0.92   |   388   |\n",
      "|    1     |    0.91   |  0.30  |   0.45   |    33   |\n",
      "|    2     |    0.00   |  0.00  |   0.00   |    5    |\n",
      "|    3     |    0.25   |  0.05  |   0.08   |    22   |\n",
      "|    4     |    0.00   |  0.00  |   0.00   |    7    |\n",
      "|    5     |    0.00   |  0.00  |   0.00   |    3    |\n",
      "|    6     |    0.00   |  0.00  |   0.00   |    7    |\n",
      "|    7     |    0.00   |  0.00  |   0.00   |    5    |\n",
      "+----------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "report_data = report.split('\\n')\n",
    "table = PrettyTable([\"Category\"] + report_data[0].split())\n",
    "for line in report_data[2:-5]:\n",
    "    table.add_row(line.split())\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e861580-e47e-456b-9816-9db6c4ffb6a7",
   "metadata": {},
   "source": [
    "TODO: Figure out which metric we care about in the imbalanced setting??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7b64b-96da-482f-a997-5ea44596ca3e",
   "metadata": {},
   "source": [
    "### Re-Balancing Training Data\n",
    "\n",
    "We can try this in a few ways ways:\n",
    "\n",
    "1. Upsampling minority classes\n",
    "2. Class Weighted Loss\n",
    "\n",
    "First we will start simple with oversampling minority classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a9cfa-be7d-4163-8ca9-a0bf14bf6feb",
   "metadata": {},
   "source": [
    "#### Oversampling minority classes\n",
    "\n",
    "We will oversample minority classes to the size of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ad7b8047-d5e0-4e7c-8df5-098f149d0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/w3zvknms6yvf104977q75_jm0000gn/T/ipykernel_68607/1917138588.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  upsampled_data = pd.concat([upsampled_data, minority_upsampled])\n"
     ]
    }
   ],
   "source": [
    "class_counts = y_train['LET_IS'].value_counts()\n",
    "minority_classes = class_counts[class_counts != class_counts.max()].index\n",
    "columns = list(X_train.columns) + list(y_train.columns)\n",
    "upsampled_data = pd.DataFrame(columns=columns)\n",
    "combined_df = pd.DataFrame(np.hstack((X_train_imputed, np.array(y_train))), columns = columns)\n",
    "\n",
    "for minority_class in minority_classes:\n",
    "    # Subset the minority class instances\n",
    "    minority_data = combined_df[combined_df['LET_IS'] == minority_class]\n",
    "\n",
    "    # Oversample the minority class to match the size of the majority class\n",
    "    minority_upsampled = resample(minority_data, replace=True, n_samples=class_counts.max(), random_state=42)\n",
    "\n",
    "    # Add the upsampled data to the DataFrame\n",
    "    upsampled_data = pd.concat([upsampled_data, minority_upsampled])\n",
    "\n",
    "# Combine the upsampled data with the majority class data\n",
    "balanced_data = pd.concat([combined_df[combined_df['LET_IS'] == 0], upsampled_data])\n",
    "\n",
    "# Separate the features and target variable from the upsampled data\n",
    "X_train_upsampled = np.array(balanced_data.drop(y_train.columns, axis=1))\n",
    "y_train_upsampled = balanced_data[y_train.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a6d7a947-dc8b-4729-837e-9522367696eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model and make predictions as usual\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', penalty = 'l1')\n",
    "model.fit(X_train_upsampled, y_train_upsampled[])\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['LET_IS'], y_pred)\n",
    "report = classification_report(y_test['LET_IS'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "940ec8b4-39da-4928-94e9-9c30e19e786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6340425531914894\n",
      "+----------+-----------+--------+----------+---------+\n",
      "| Category | precision | recall | f1-score | support |\n",
      "+----------+-----------+--------+----------+---------+\n",
      "|    0     |    0.92   |  0.71  |   0.80   |   388   |\n",
      "|    1     |    0.33   |  0.45  |   0.38   |    33   |\n",
      "|    2     |    0.10   |  0.20  |   0.13   |    5    |\n",
      "|    3     |    0.10   |  0.18  |   0.12   |    22   |\n",
      "|    4     |    0.08   |  0.14  |   0.11   |    7    |\n",
      "|    5     |    0.00   |  0.00  |   0.00   |    3    |\n",
      "|    6     |    0.00   |  0.00  |   0.00   |    7    |\n",
      "|    7     |    0.00   |  0.00  |   0.00   |    5    |\n",
      "+----------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# our accuracy takes a hit, but we have better recall in four more classes. \n",
    "print(accuracy)\n",
    "report_data = report.split('\\n')\n",
    "table = PrettyTable([\"Category\"] + report_data[0].split())\n",
    "for line in report_data[2:-5]:\n",
    "    table.add_row(line.split())\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8223fa06-e018-463e-b72f-8a15830efdea",
   "metadata": {},
   "source": [
    "#### Reweighting Classes\n",
    "\n",
    "We can also try to assign different weights to classes to give more importance to minority classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7757998b-0c51-4c9a-95bc-d999be345ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train['LET_IS']), y=y_train['LET_IS'])\n",
    "\n",
    "# Create a dictionary with class weights\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# train model and make predictions as usual\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', penalty = 'l1', class_weight=class_weight_dict)\n",
    "model.fit(X_train_imputed, y_train['LET_IS'])\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['LET_IS'], y_pred)\n",
    "report = classification_report(y_test['LET_IS'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "271581dc-eab4-4e8c-9d5b-53cc9d0da4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7574468085106383\n",
      "+----------+-----------+--------+----------+---------+\n",
      "| Category | precision | recall | f1-score | support |\n",
      "+----------+-----------+--------+----------+---------+\n",
      "|    0     |    0.91   |  0.87  |   0.89   |   388   |\n",
      "|    1     |    0.52   |  0.39  |   0.45   |    33   |\n",
      "|    2     |    0.10   |  0.20  |   0.13   |    5    |\n",
      "|    3     |    0.22   |  0.23  |   0.22   |    22   |\n",
      "|    4     |    0.00   |  0.00  |   0.00   |    7    |\n",
      "|    5     |    0.00   |  0.00  |   0.00   |    3    |\n",
      "|    6     |    0.00   |  0.00  |   0.00   |    7    |\n",
      "|    7     |    0.00   |  0.00  |   0.00   |    5    |\n",
      "+----------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# our accuracy is better than before, but still poor performance on the smaller classes \n",
    "print(accuracy)\n",
    "report_data = report.split('\\n')\n",
    "table = PrettyTable([\"Category\"] + report_data[0].split())\n",
    "for line in report_data[2:-5]:\n",
    "    table.add_row(line.split())\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39bd84-405b-40fb-9033-eb572f0d1e36",
   "metadata": {},
   "source": [
    "### Consolidating Classes\n",
    "\n",
    "\n",
    "We can also try to consolidate our classes so that we have more manageable outcomes. According to chatgpt:\n",
    "\n",
    "Cardiac Complications:\n",
    "Cardiogenic shock (1)\n",
    "Myocardial rupture (3)\n",
    "Progress of congestive heart failure (4)\n",
    "These conditions are all related to the function and complications of the heart. They could be grouped together as \"Cardiac Complications.\"\n",
    "\n",
    "Pulmonary/Cardiopulmonary Complications:\n",
    "Pulmonary edema (2)\n",
    "Thromboembolism (5)\n",
    "Both of these conditions involve complications in the pulmonary system or the interaction between the heart and the lungs.\n",
    "\n",
    "Cardiac Arrest:\n",
    "Asystole (6)\n",
    "Ventricular fibrillation (7)\n",
    "Both asystole and ventricular fibrillation are types of cardiac arrest. You could group them together as \"Cardiac Arrest.\"\n",
    "\n",
    "\n",
    "We will upsample our data according to these four classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d1f89d75-0bb9-42c1-a51b-1651165a7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y_train['cause_of_death'].value_counts()\n",
    "minority_classes = class_counts[class_counts != class_counts.max()].index\n",
    "columns = list(X_train.columns) + list(y_train.columns)\n",
    "upsampled_data = pd.DataFrame(columns=columns)\n",
    "combined_df = pd.DataFrame(np.hstack((X_train_imputed, np.array(y_train))), columns = columns)\n",
    "\n",
    "for minority_class in minority_classes:\n",
    "    # Subset the minority class instances\n",
    "    minority_data = combined_df[combined_df['cause_of_death'] == minority_class]\n",
    "\n",
    "    # Oversample the minority class to match the size of the majority class\n",
    "    minority_upsampled = resample(minority_data, replace=True, n_samples=class_counts.max(), random_state=42)\n",
    "\n",
    "    # Add the upsampled data to the DataFrame\n",
    "    upsampled_data = pd.concat([upsampled_data, minority_upsampled])\n",
    "\n",
    "# Combine the upsampled data with the majority class data\n",
    "balanced_data = pd.concat([combined_df[combined_df['cause_of_death'] == 'alive'], upsampled_data])\n",
    "\n",
    "# Separate the features and target variable from the upsampled data\n",
    "X_train_upsampled = np.array(balanced_data.drop(y_train.columns, axis=1))\n",
    "y_train_upsampled = balanced_data[y_train.columns]\n",
    "\n",
    "\n",
    "# our accuracy takes a hit, but we have better recall in four more classes. \n",
    "# train model and make predictions as usual\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', penalty = 'l1')\n",
    "model.fit(X_train_upsampled, y_train_upsampled['cause_of_death'])\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['cause_of_death'], y_pred)\n",
    "report = classification_report(y_test['cause_of_death'], y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "80947c58-adbd-4c2b-9b80-25f5afb71859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6702127659574468\n",
      "+-------------------------+-----------+--------+----------+---------+\n",
      "|         Category        | precision | recall | f1-score | support |\n",
      "+-------------------------+-----------+--------+----------+---------+\n",
      "|          alive          |    0.94   |  0.73  |   0.82   |   388   |\n",
      "|      cardiac_arrest     |    0.03   |  0.17  |   0.05   |    12   |\n",
      "|  cardiac_complications  |    0.38   |  0.45  |   0.41   |    62   |\n",
      "| pulmonary_complications |    0.04   |  0.12  |   0.06   |    8    |\n",
      "+-------------------------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# understandably, we are still performing poorly on the lower classes, but we should consider the support.\n",
    "# there are so few observations in these classes still. \n",
    "print(accuracy)\n",
    "report_data = report.split('\\n')\n",
    "table = PrettyTable([\"Category\"] + report_data[0].split())\n",
    "for line in report_data[2:-5]:\n",
    "    table.add_row(line.split())\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1f1f0-9905-4164-9587-7119f825cfa3",
   "metadata": {},
   "source": [
    "# Remaining Tasks\n",
    "\n",
    "1. Write out intro, describing our major problems of interest and what we plan to do to address each of these. \n",
    "2. Describe dataset features (time of collection), targets of interest, and initial dataset preprocessing (we should probably look into what these targets actually are)\n",
    "3. Plots/Tables: Percentage of various outcomes, table showing amount of overlap between possible outcomes, maybe some plots of outcome vs. feature\n",
    "4. Simple binary classification with logistic regression-- explain how we did lasso for convergence and report confusion matrix (formatted nicely). Say that we have a decent accuracy and that our outcomes are quite balanced here. But we can do better in terms of accuracy and our next steps in the binary classification setting are to explore \n",
    "5. Then say that we also have a multi-class classification problem of interest, where imbalance is a much greater problem. Talk about the specific setup and what metrics we will need to use. We have so far tried 1) no rebalancing, 2) upsampling, 3) reweighting, and 4) consolidating classes and upsampling again. So far doesn't look like we do great in any case so this data just might not be ideal. So for our next steps, we are going to turn to either 1) just predicting this as a binary outcome or 2) using multi-label classification to predict multiple outcomes for a patient. For these we will again try simple LR and then move over to deep learning techniques. If we do multi-label then we may just select a few relevant ones instead of 13 (or however many there are). \n",
    "\n",
    "And organize everything into:\n",
    "\n",
    "Motivation: What problem are you tackling, and what's the setting you're considering?\n",
    "Method: What machine learning techniques have you tried and why?\n",
    "Preliminary experiments: Describe the experiments that you've run, the outcomes, and any error analysis that you've done. You should have tried at least one baseline.\n",
    "Next steps: Given your preliminary results, what are the next steps that you're considering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a028207-9fa9-4b3d-87ae-49499a96f36e",
   "metadata": {},
   "source": [
    "# Code Backlog -- THINGS I TRIED THAT DIDN'T DO ANYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db903361-089b-4808-b9d3-9e89cb4e5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually do cross validation to see if we can find a good \n",
    "# combination of C (lasso regularization parameter) and n (KNN parameter)\n",
    "# Can make a note that we tried this but it made very little difference\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ns = [1, 3, 5, 10, 15, 20, 30, 50]\n",
    "cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "n_repeats = 3\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "def manual_cv_logreg(X, y, ns, cs, n_repeats): \n",
    "    for n in ns:\n",
    "        for c in cs:\n",
    "            print(f\"n: {n}, c: {c}\")    \n",
    "            repeat_results = []  \n",
    "            for repeat in range(n_repeats):\n",
    "                #print(f\"Repeat {repeat + 1}/{n_repeats}\")\n",
    "    \n",
    "                # Create a KFold cross-validator with 'n_splits' folds\n",
    "                kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "                # Initialize a list to store the cross-validation results for this repeat\n",
    "                fold_results = []\n",
    "    \n",
    "                for train_idx, test_idx in kf.split(X):\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "                    # impute \n",
    "                    X_train_imputed = impute_values(X_train, n)\n",
    "                    X_test_imputed = impute_values(X_test, n)\n",
    "\n",
    "                    #train model\n",
    "                    model = LogisticRegression(penalty = \"l1\", solver='liblinear')\n",
    "                    model.fit(X_train_imputed, y_train)\n",
    "\n",
    "                    # make predictions on test data\n",
    "                    y_pred = model.predict(X_test_imputed)\n",
    "    \n",
    "                    # Calculate the accuracy or other evaluation metric\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    fold_results.append(accuracy)\n",
    "    \n",
    "                # Calculate the mean accuracy and standard deviation for this repeat\n",
    "                mean_accuracy = sum(fold_results) / len(fold_results)\n",
    "                std_accuracy = (sum((x - mean_accuracy) ** 2 for x in fold_results) / len(fold_results)) ** 0.5\n",
    "    \n",
    "                #print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "                #print(f\"Std. Deviation: {std_accuracy:.4f}\\n\")\n",
    "    \n",
    "                repeat_results.append(mean_accuracy)\n",
    "    \n",
    "            # Calculate the overall mean accuracy across repeats for this parameter combination\n",
    "            overall_mean_accuracy = sum(repeat_results) / len(repeat_results)\n",
    "            results.append((n, c, overall_mean_accuracy))\n",
    "    \n",
    "    # Find the best parameter combination\n",
    "    best_params = max(results, key=lambda x: x[2])\n",
    "    print(f\"Best Parameters: Parameter 1 = {best_params[0]}, Parameter 2 = {best_params[1]}\")\n",
    "    return best_params\n",
    "\n",
    "\n",
    "manual_cv_logreg(X_train, y_train['any_event'], ns, cs, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676305ed-cdc5-4f0d-871c-2727a46e85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out a random forest model???\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train_upsampled, y_train_upsampled['LET_IS'])\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "accuracy = accuracy_score(y_test['LET_IS'], y_pred)\n",
    "report = classification_report(y_test['LET_IS'], y_pred)\n",
    "\n",
    "# our accuracy takes a hit, but we have better recall in four more classes. \n",
    "print(accuracy)\n",
    "report_data = report.split('\\n')\n",
    "table = PrettyTable([\"Category\"] + report_data[0].split())\n",
    "for line in report_data[2:-5]:\n",
    "    table.add_row(line.split())\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c323b-9534-4c06-b541-cb069a1f3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-output regression\n",
    "y_train_moutput = y_train[['FIBR_PREDS', 'PREDS_TAH', 'JELUD_TAH', 'FIBR_JELUD', 'A_V_BLOK',\n",
    "       'OTEK_LANC', 'RAZRIV', 'DRESSLER', 'ZSN', 'REC_IM', 'P_IM_STEN']]\n",
    "y_test_moutput = y_test[['FIBR_PREDS', 'PREDS_TAH', 'JELUD_TAH', 'FIBR_JELUD', 'A_V_BLOK',\n",
    "       'OTEK_LANC', 'RAZRIV', 'DRESSLER', 'ZSN', 'REC_IM', 'P_IM_STEN']]\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "logistic_reg = LogisticRegression(penalty = \"l1\", solver='liblinear')\n",
    "multioutput_classifier = MultiOutputClassifier(logistic_reg)\n",
    "multioutput_classifier.fit(X_train_imputed, y_train_moutput)\n",
    "\n",
    "\n",
    "y_pred = multioutput_classifier.predict(X_test_imputed)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_moutput, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_moutput, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
